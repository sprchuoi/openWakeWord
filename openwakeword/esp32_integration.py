"""
ESP32 Integration Module for openWakeWord
Provides I2S audio capture and real-time wake word detection on ESP32 microcontrollers.

This module is designed to work with ESP32-based smart home systems and includes:
- I2S audio interface configuration
- Real-time audio buffering and processing
- Wake word detection with the ModelLoader framework
- Low-power optimization strategies
"""

import numpy as np
from typing import Optional, Callable, Dict, Any
import logging
from collections import deque
import time


class ESP32AudioConfig:
    """Configuration for ESP32 I2S audio interface."""
    
    def __init__(self,
                 sample_rate: int = 16000,
                 bits_per_sample: int = 16,
                 channels: int = 1,
                 buffer_size: int = 1280,  # 80ms at 16kHz
                 dma_buffer_count: int = 8,
                 dma_buffer_size: int = 320):
        """
        Initialize ESP32 audio configuration.
        
        Args:
            sample_rate: Audio sample rate in Hz (8000, 16000, 22050, 44100)
            bits_per_sample: Bits per audio sample (16, 24, 32)
            channels: Number of audio channels (1 for mono, 2 for stereo)
            buffer_size: Size of audio buffer in samples (affects latency)
            dma_buffer_count: Number of DMA buffers for I2S
            dma_buffer_size: Size of each DMA buffer in samples
        """
        self.sample_rate = sample_rate
        self.bits_per_sample = bits_per_sample
        self.channels = channels
        self.buffer_size = buffer_size
        self.dma_buffer_count = dma_buffer_count
        self.dma_buffer_size = dma_buffer_size
        
        # Calculate derived parameters
        self.bytes_per_sample = bits_per_sample // 8
        self.buffer_duration_ms = (buffer_size / sample_rate) * 1000
        
    def to_dict(self) -> Dict[str, Any]:
        """Export configuration as dictionary for serialization."""
        return {
            'sample_rate': self.sample_rate,
            'bits_per_sample': self.bits_per_sample,
            'channels': self.channels,
            'buffer_size': self.buffer_size,
            'dma_buffer_count': self.dma_buffer_count,
            'dma_buffer_size': self.dma_buffer_size
        }


class I2SAudioCapture:
    """
    I2S audio capture interface for ESP32.
    
    This is a Python-side implementation that generates the necessary
    configuration and code templates for ESP32 deployment.
    """
    
    def __init__(self, config: ESP32AudioConfig):
        """
        Initialize I2S audio capture.
        
        Args:
            config: ESP32AudioConfig instance with I2S settings
        """
        self.config = config
        self.logger = logging.getLogger(self.__class__.__name__)
        self.audio_buffer = deque(maxlen=config.buffer_size * 10)  # 10 buffer history
        self.is_running = False
        
    def generate_esp32_config(self) -> str:
        """
        Generate ESP32 Arduino/ESP-IDF configuration code.
        
        Returns:
            str: C/C++ code for ESP32 I2S configuration
        """
        config_code = f"""
// ESP32 I2S Configuration for Wake Word Detection
// Generated by openWakeWord ESP32 Integration

#include <driver/i2s.h>

// I2S Configuration
#define SAMPLE_RATE {self.config.sample_rate}
#define BITS_PER_SAMPLE {self.config.bits_per_sample}
#define CHANNELS {self.config.channels}
#define BUFFER_SIZE {self.config.buffer_size}
#define DMA_BUFFER_COUNT {self.config.dma_buffer_count}
#define DMA_BUFFER_SIZE {self.config.dma_buffer_size}

// I2S Pin Configuration (adjust for your hardware)
#define I2S_WS_PIN 15      // LRCLK (Word Select)
#define I2S_SCK_PIN 14     // BCLK (Bit Clock)
#define I2S_SD_PIN 32      // SD (Serial Data)

const i2s_config_t i2s_config = {{
    .mode = (i2s_mode_t)(I2S_MODE_MASTER | I2S_MODE_RX),
    .sample_rate = SAMPLE_RATE,
    .bits_per_sample = (i2s_bits_per_sample_t)BITS_PER_SAMPLE,
    .channel_format = I2S_CHANNEL_FMT_ONLY_LEFT,
    .communication_format = I2S_COMM_FORMAT_I2S,
    .intr_alloc_flags = ESP_INTR_FLAG_LEVEL1,
    .dma_buf_count = DMA_BUFFER_COUNT,
    .dma_buf_len = DMA_BUFFER_SIZE,
    .use_apll = false,
    .tx_desc_auto_clear = false,
    .fixed_mclk = 0
}};

const i2s_pin_config_t pin_config = {{
    .bck_io_num = I2S_SCK_PIN,
    .ws_io_num = I2S_WS_PIN,
    .data_out_num = I2S_PIN_NO_CHANGE,
    .data_in_num = I2S_SD_PIN
}};

void setup_i2s() {{
    // Install I2S driver
    i2s_driver_install(I2S_NUM_0, &i2s_config, 0, NULL);
    i2s_set_pin(I2S_NUM_0, &pin_config);
    i2s_zero_dma_buffer(I2S_NUM_0);
}}

// Audio capture function
void capture_audio(int16_t* buffer, size_t buffer_len) {{
    size_t bytes_read = 0;
    i2s_read(I2S_NUM_0, buffer, buffer_len * sizeof(int16_t), &bytes_read, portMAX_DELAY);
}}
"""
        return config_code
    
    def generate_micropython_config(self) -> str:
        """
        Generate MicroPython I2S configuration code.
        
        Returns:
            str: MicroPython code for ESP32 I2S configuration
        """
        config_code = f"""
# ESP32 I2S Configuration for Wake Word Detection (MicroPython)
# Generated by openWakeWord ESP32 Integration

from machine import I2S, Pin
import array

# I2S Configuration
SAMPLE_RATE = {self.config.sample_rate}
BITS_PER_SAMPLE = {self.config.bits_per_sample}
BUFFER_SIZE = {self.config.buffer_size}

# I2S Pin Configuration (adjust for your hardware)
SCK_PIN = 14   # Bit Clock
WS_PIN = 15    # Word Select
SD_PIN = 32    # Serial Data

# Initialize I2S
audio_in = I2S(
    0,
    sck=Pin(SCK_PIN),
    ws=Pin(WS_PIN),
    sd=Pin(SD_PIN),
    mode=I2S.RX,
    bits=BITS_PER_SAMPLE,
    format=I2S.MONO,
    rate=SAMPLE_RATE,
    ibuf=BUFFER_SIZE * 2
)

# Audio capture function
def capture_audio(num_samples={self.config.buffer_size}):
    audio_buffer = bytearray(num_samples * 2)  # 16-bit samples
    num_read = audio_in.readinto(audio_buffer)
    # Convert to signed int16 array
    samples = array.array('h', audio_buffer)
    return samples
"""
        return config_code
    
    def simulate_capture(self, duration_ms: int = 100) -> np.ndarray:
        """
        Simulate audio capture for testing (generates synthetic data).
        
        Args:
            duration_ms: Duration of audio to simulate in milliseconds
            
        Returns:
            np.ndarray: Simulated audio samples
        """
        num_samples = int((duration_ms / 1000) * self.config.sample_rate)
        # Generate some synthetic audio (noise + sine wave)
        t = np.linspace(0, duration_ms / 1000, num_samples)
        audio = 0.1 * np.random.randn(num_samples) + 0.05 * np.sin(2 * np.pi * 440 * t)
        
        # Convert to int16 range
        audio = (audio * 32767).astype(np.int16)
        
        return audio


class ESP32WakeWordDetector:
    """
    Complete wake word detection system for ESP32.
    Integrates audio capture, preprocessing, and model inference.
    """
    
    def __init__(self,
                 model_loader,
                 audio_config: Optional[ESP32AudioConfig] = None,
                 detection_threshold: float = 0.5,
                 smoothing_window: int = 5):
        """
        Initialize ESP32 wake word detector.
        
        Args:
            model_loader: Instance of ModelLoader (Placeholder, EdgeImpulse, or Custom)
            audio_config: ESP32AudioConfig instance (uses default if None)
            detection_threshold: Threshold for wake word detection (0.0 to 1.0)
            smoothing_window: Number of frames to smooth detection scores
        """
        self.model_loader = model_loader
        self.audio_config = audio_config or ESP32AudioConfig()
        self.audio_capture = I2SAudioCapture(self.audio_config)
        self.detection_threshold = detection_threshold
        self.smoothing_window = smoothing_window
        
        self.logger = logging.getLogger(self.__class__.__name__)
        self.detection_scores = deque(maxlen=smoothing_window)
        self.frame_count = 0
        
        # Load model
        if not self.model_loader.load():
            raise RuntimeError("Failed to load model")
        
        self.logger.info(f"Initialized ESP32 Wake Word Detector")
        self.logger.info(f"Model input shape: {self.model_loader.get_input_shape()}")
        self.logger.info(f"Detection threshold: {self.detection_threshold}")
    
    def process_audio_frame(self, audio_data: np.ndarray) -> float:
        """
        Process a single audio frame and return detection score.
        
        Args:
            audio_data: Raw audio samples (int16 or float32)
            
        Returns:
            float: Detection score (0.0 to 1.0)
        """
        # Normalize audio to [-1, 1]
        if audio_data.dtype == np.int16:
            audio_data = audio_data.astype(np.float32) / 32768.0
        
        # Prepare input for model
        model_input_shape = self.model_loader.get_input_shape()
        
        # Handle different input shapes
        if len(model_input_shape) == 1:
            # Direct audio input (e.g., PlaceholderModelLoader)
            if audio_data.shape[0] != model_input_shape[0]:
                # Resize if needed
                if audio_data.shape[0] < model_input_shape[0]:
                    audio_data = np.pad(audio_data, (0, model_input_shape[0] - audio_data.shape[0]))
                else:
                    audio_data = audio_data[:model_input_shape[0]]
            input_features = audio_data
        else:
            # Feature-based input (e.g., spectrogram)
            # For now, reshape audio to match expected input
            # In practice, you'd compute MFCCs or spectrograms here
            target_size = np.prod(model_input_shape)
            if audio_data.size < target_size:
                audio_data = np.pad(audio_data, (0, target_size - audio_data.size))
            elif audio_data.size > target_size:
                audio_data = audio_data[:target_size]
            input_features = audio_data.reshape(model_input_shape)
        
        # Run inference
        prediction = self.model_loader.predict(input_features)
        
        # Extract score (handle different output shapes)
        if isinstance(prediction, np.ndarray):
            score = float(prediction.flatten()[0])
        else:
            score = float(prediction)
        
        # Smooth score
        self.detection_scores.append(score)
        smoothed_score = np.mean(self.detection_scores)
        
        self.frame_count += 1
        
        return smoothed_score
    
    def detect(self, audio_data: np.ndarray) -> tuple:
        """
        Detect wake word in audio data.
        
        Args:
            audio_data: Audio samples to analyze
            
        Returns:
            tuple: (detected: bool, score: float)
        """
        score = self.process_audio_frame(audio_data)
        detected = score >= self.detection_threshold
        
        if detected:
            self.logger.info(f"Wake word detected! Score: {score:.3f}")
        
        return detected, score
    
    def generate_deployment_package(self, output_dir: str):
        """
        Generate complete deployment package for ESP32.
        
        Args:
            output_dir: Directory to save deployment files
        """
        import os
        import json
        
        os.makedirs(output_dir, exist_ok=True)
        
        # Save I2S configuration
        arduino_config = self.audio_capture.generate_esp32_config()
        with open(os.path.join(output_dir, "i2s_config.h"), 'w') as f:
            f.write(arduino_config)
        
        micropython_config = self.audio_capture.generate_micropython_config()
        with open(os.path.join(output_dir, "i2s_config.py"), 'w') as f:
            f.write(micropython_config)
        
        # Save detector configuration
        detector_config = {
            'audio_config': self.audio_config.to_dict(),
            'detection_threshold': self.detection_threshold,
            'smoothing_window': self.smoothing_window,
            'model_input_shape': self.model_loader.get_input_shape(),
            'model_output_shape': self.model_loader.get_output_shape()
        }
        
        with open(os.path.join(output_dir, "detector_config.json"), 'w') as f:
            json.dump(detector_config, f, indent=2)
        
        # Export model if supported
        if hasattr(self.model_loader, 'export_for_esp32'):
            model_path = os.path.join(output_dir, "model.tflite")
            self.model_loader.export_for_esp32(model_path)
        
        # Generate README
        readme = self._generate_readme()
        with open(os.path.join(output_dir, "README.md"), 'w') as f:
            f.write(readme)
        
        self.logger.info(f"Deployment package generated in {output_dir}")
    
    def _generate_readme(self) -> str:
        """Generate README for ESP32 deployment."""
        return f"""# ESP32 Wake Word Detection Deployment Package

Generated by openWakeWord ESP32 Integration

## Hardware Requirements

- ESP32 development board (ESP32, ESP32-S3, etc.)
- I2S microphone (e.g., INMP441, SPH0645, ICS-43434)
- USB cable for programming

## Audio Configuration

- Sample Rate: {self.audio_config.sample_rate} Hz
- Bits per Sample: {self.audio_config.bits_per_sample}
- Channels: {self.audio_config.channels}
- Buffer Size: {self.audio_config.buffer_size} samples ({self.audio_config.buffer_duration_ms:.1f} ms)

## I2S Pin Configuration

Default pin configuration (adjust in code as needed):
- SCK (Bit Clock): GPIO 14
- WS (Word Select): GPIO 15
- SD (Serial Data): GPIO 32

## Detection Parameters

- Threshold: {self.detection_threshold}
- Smoothing Window: {self.smoothing_window} frames
- Model Input Shape: {self.model_loader.get_input_shape()}

## Arduino IDE Setup

1. Install ESP32 board support in Arduino IDE
2. Copy `i2s_config.h` to your Arduino sketch folder
3. Include the configuration: `#include "i2s_config.h"`
4. Call `setup_i2s()` in your `setup()` function
5. Use `capture_audio()` to read audio samples

## MicroPython Setup

1. Flash MicroPython firmware to ESP32
2. Copy `i2s_config.py` to the ESP32 filesystem
3. Import the configuration: `from i2s_config import capture_audio`
4. Call `capture_audio()` to read audio samples

## Integration Example

```cpp
// Arduino example
#include "i2s_config.h"

void setup() {{
    Serial.begin(115200);
    setup_i2s();
}}

void loop() {{
    int16_t buffer[BUFFER_SIZE];
    capture_audio(buffer, BUFFER_SIZE);
    
    // Process audio with wake word detection model
    float score = detect_wake_word(buffer);
    
    if (score > {self.detection_threshold}) {{
        Serial.println("Wake word detected!");
    }}
}}
```

## Performance Tips

1. Use energy-based pre-filtering to reduce CPU load
2. Adjust buffer size for latency vs. accuracy tradeoff
3. Consider using ESP32-S3 for better performance
4. Enable PSRAM for larger models
5. Use hardware acceleration (XNNPACK) when available

## Troubleshooting

- **No audio**: Check I2S pin connections and microphone power
- **Noisy audio**: Verify proper grounding and power supply
- **High latency**: Reduce buffer size or DMA buffer count
- **False positives**: Increase detection threshold
- **Missed detections**: Decrease threshold or retrain model

## Resources

- [ESP32 I2S Documentation](https://docs.espressif.com/projects/esp-idf/en/latest/esp32/api-reference/peripherals/i2s.html)
- [openWakeWord Documentation](https://github.com/dscripka/openWakeWord)
"""

    def benchmark_performance(self, num_iterations: int = 100) -> Dict[str, float]:
        """
        Benchmark inference performance on simulated audio.
        
        Args:
            num_iterations: Number of inference iterations
            
        Returns:
            dict: Performance metrics
        """
        self.logger.info(f"Running performance benchmark ({num_iterations} iterations)...")
        
        # Generate test audio
        test_audio = self.audio_capture.simulate_capture(
            duration_ms=int(self.audio_config.buffer_duration_ms)
        )
        
        # Warm-up
        for _ in range(10):
            self.process_audio_frame(test_audio)
        
        # Benchmark
        times = []
        for _ in range(num_iterations):
            start = time.time()
            self.process_audio_frame(test_audio)
            times.append(time.time() - start)
        
        times = np.array(times) * 1000  # Convert to ms
        
        metrics = {
            'mean_inference_time_ms': float(np.mean(times)),
            'std_inference_time_ms': float(np.std(times)),
            'min_inference_time_ms': float(np.min(times)),
            'max_inference_time_ms': float(np.max(times)),
            'throughput_fps': 1000.0 / np.mean(times),
            'real_time_factor': self.audio_config.buffer_duration_ms / np.mean(times)
        }
        
        self.logger.info(f"Performance Results:")
        self.logger.info(f"  Mean inference time: {metrics['mean_inference_time_ms']:.2f} ms")
        self.logger.info(f"  Throughput: {metrics['throughput_fps']:.1f} FPS")
        self.logger.info(f"  Real-time factor: {metrics['real_time_factor']:.1f}x")
        
        return metrics
